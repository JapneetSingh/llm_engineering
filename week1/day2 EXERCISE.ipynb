{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% ▕████████████████▏ 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% ▕████████████████▏   96 B                         \n",
      "pulling 34bb5ab01051... 100% ▕████████████████▏  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to create high-quality content such as text, images, and videos. For example, AI-powered writing tools can generate articles, product descriptions, and social media posts.\n",
      "2. **Marketing Automation**: Generative AI can help automate marketing campaigns by generating personalized content, offers, and emails for customers. This can lead to increased engagement, conversion rates, and customer loyalty.\n",
      "3. **Product Design**: Generative AI can be used to design new products, such as 3D models, product prototypes, and packaging designs. This can save time and resources, while also improving the quality of the final product.\n",
      "4. **Customer Service**: Generative AI can help create personalized customer service chatbots that can respond to customer inquiries and provide support.\n",
      "5. **Data Analysis**: Generative AI can be used to analyze large datasets and identify patterns, trends, and insights. This can help businesses make data-driven decisions and improve their operations.\n",
      "6. **Supply Chain Optimization**: Generative AI can be used to optimize supply chain operations by predicting demand, managing inventory, and identifying bottlenecks.\n",
      "7. **Financial Analysis**: Generative AI can be used to analyze financial data, identify trends, and predict future market behavior.\n",
      "8. **Image and Video Editing**: Generative AI can be used to edit images and videos, creating realistic effects such as removing backgrounds or adding special effects.\n",
      "9. **Language Translation**: Generative AI can be used to translate languages in real-time, improving communication between businesses and customers across different regions.\n",
      "10. **Cybersecurity**: Generative AI can be used to detect and prevent cyber threats by analyzing network traffic and identifying potential vulnerabilities.\n",
      "\n",
      "Some specific business applications of Generative AI include:\n",
      "\n",
      "* **Chatbots**: Generative AI can be used to create chatbots that can respond to customer inquiries, provide support, and engage in conversations.\n",
      "* **Personalized Recommendations**: Generative AI can be used to generate personalized product recommendations based on customer behavior and preferences.\n",
      "* **Predictive Maintenance**: Generative AI can be used to predict equipment failures and schedule maintenance, reducing downtime and improving efficiency.\n",
      "* **Automated Content Moderation**: Generative AI can be used to automate content moderation, identifying and removing sensitive or objectionable content.\n",
      "* **Digital Twinning**: Generative AI can be used to create digital twins of physical assets, such as buildings, machines, and products, allowing businesses to simulate and optimize their operations.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf80633c-ff27-45b2-b7da-51e87c589fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gh/d6gtsgsn3jj_gz0176vm13s40000gn/T/ipykernel_86381/690762135.py:1: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  response.json()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"model\":\"llama3.2\",\"created_at\":\"2025-03-05T02:43:58.641224Z\",\"done\":true,\"done_reason\":\"stop\",\"total_duration\":9711528334,\"load_duration\":14134459,\"prompt_eval_count\":35,\"prompt_eval_duration\":23000000,\"eval_count\":504,\"eval_duration\":9673000000,\"message\":{\"role\":\"assistant\",\"content\":\"Generative AI has numerous business applications across various industries. Here are some examples:\\\\n\\\\n1. **Content Creation**: Generative AI can be used to create high-quality content such as blog posts, articles, social media posts, and product descriptions. This can help businesses save time and resources while maintaining consistency in their content.\\\\n2. **Image and Video Generation**: Generative AI can generate realistic images and videos for use in advertising, marketing campaigns, and entertainment. For example, it can create custom product images or video content for social media.\\\\n3. **Chatbots and Virtual Assistants**: Generative AI can be used to power chatbots and virtual assistants, enabling businesses to provide personalized customer support and improve user experience.\\\\n4. **Marketing and Advertising**: Generative AI can help businesses generate personalized marketing messages, create targeted ads, and predict consumer behavior.\\\\n5. **Product Design**: Generative AI can be used to design new products, such as furniture, clothing, or electronics, by generating 3D models and prototypes.\\\\n6. **Data Analysis and Visualization**: Generative AI can analyze large datasets and generate visualizations to help businesses understand complex data patterns and trends.\\\\n7. **Predictive Maintenance**: Generative AI can be used to predict equipment failures and maintenance needs, helping businesses reduce downtime and improve overall efficiency.\\\\n8. **Customer Service**: Generative AI-powered chatbots can help businesses provide 24/7 customer support and answer frequently asked questions.\\\\n9. **Speech Recognition and Synthesis**: Generative AI can be used to improve speech recognition systems and generate synthetic voices for use in voice assistants, podcasts, and audiobooks.\\\\n10. **Creative Writing**: Generative AI can assist writers with content creation, such as generating ideas, outlining articles, or even composing entire pieces of writing.\\\\n\\\\nSome industries that are already leveraging generative AI include:\\\\n\\\\n1. **Finance**: Using generative AI to analyze financial data, predict market trends, and create personalized investment advice.\\\\n2. **Healthcare**: Using generative AI to develop personalized treatment plans, generate medical images, and predict patient outcomes.\\\\n3. **Retail**: Using generative AI to personalize product recommendations, improve inventory management, and create immersive customer experiences.\\\\n4. **Education**: Using generative AI to create personalized learning content, grade assignments, and provide feedback.\\\\n\\\\nThese are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\",\"images\":null,\"tool_calls\":null}}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf74c4f7-b637-463d-bf98-458a448c0e7b",
   "metadata": {},
   "source": [
    "Generative AI has numerous business applications across various industries, including:\n",
    "\n",
    "1. **Content Creation**: Generative AI can be used to create high-quality content such as text, images, and videos. For example, AI-powered writing tools can generate articles, product descriptions, and social media posts.\n",
    "2. **Marketing Automation**: Generative AI can help automate marketing campaigns by generating personalized content, offers, and emails for customers. This can lead to increased engagement, conversion rates, and customer loyalty.\n",
    "3. **Product Design**: Generative AI can be used to design new products, such as 3D models, product prototypes, and packaging designs. This can save time and resources, while also improving the quality of the final product.\n",
    "4. **Customer Service**: Generative AI can help create personalized customer service chatbots that can respond to customer inquiries and provide support.\n",
    "5. **Data Analysis**: Generative AI can be used to analyze large datasets and identify patterns, trends, and insights. This can help businesses make data-driven decisions and improve their operations.\n",
    "6. **Supply Chain Optimization**: Generative AI can be used to optimize supply chain operations by predicting demand, managing inventory, and identifying bottlenecks.\n",
    "7. **Financial Analysis**: Generative AI can be used to analyze financial data, identify trends, and predict future market behavior.\n",
    "8. **Image and Video Editing**: Generative AI can be used to edit images and videos, creating realistic effects such as removing backgrounds or adding special effects.\n",
    "9. **Language Translation**: Generative AI can be used to translate languages in real-time, improving communication between businesses and customers across different regions.\n",
    "10. **Cybersecurity**: Generative AI can be used to detect and prevent cyber threats by analyzing network traffic and identifying potential vulnerabilities.\n",
    "\n",
    "Some specific business applications of Generative AI include:\n",
    "\n",
    "* **Chatbots**: Generative AI can be used to create chatbots that can respond to customer inquiries, provide support, and engage in conversations.\n",
    "* **Personalized Recommendations**: Generative AI can be used to generate personalized product recommendations based on customer behavior and preferences.\n",
    "* **Predictive Maintenance**: Generative AI can be used to predict equipment failures and schedule maintenance, reducing downtime and improving efficiency.\n",
    "* **Automated Content Moderation**: Generative AI can be used to automate content moderation, identifying and removing sensitive or objectionable content.\n",
    "* **Digital Twinning**: Generative AI can be used to create digital twins of physical assets, such as buildings, machines, and products, allowing businesses to simulate and optimize their operations.\n",
    "\n",
    "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9923af1-01ea-4e59-8b7b-5f00023afb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gh/d6gtsgsn3jj_gz0176vm13s40000gn/T/ipykernel_86381/139212310.py:1: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  display(Markdown(response.json()['message']['content']))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m display(Markdown(\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "display(Markdown(response.json()['message']['content']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to create high-quality content such as blog posts, articles, social media posts, and product descriptions. This can help businesses save time and resources while maintaining consistency in their content.\n",
      "2. **Image and Video Generation**: Generative AI can generate realistic images and videos for use in advertising, marketing campaigns, and entertainment. For example, it can create custom product images or video content for social media.\n",
      "3. **Chatbots and Virtual Assistants**: Generative AI can be used to power chatbots and virtual assistants, enabling businesses to provide personalized customer support and improve user experience.\n",
      "4. **Marketing and Advertising**: Generative AI can help businesses generate personalized marketing messages, create targeted ads, and predict consumer behavior.\n",
      "5. **Product Design**: Generative AI can be used to design new products, such as furniture, clothing, or electronics, by generating 3D models and prototypes.\n",
      "6. **Data Analysis and Visualization**: Generative AI can analyze large datasets and generate visualizations to help businesses understand complex data patterns and trends.\n",
      "7. **Predictive Maintenance**: Generative AI can be used to predict equipment failures and maintenance needs, helping businesses reduce downtime and improve overall efficiency.\n",
      "8. **Customer Service**: Generative AI-powered chatbots can help businesses provide 24/7 customer support and answer frequently asked questions.\n",
      "9. **Speech Recognition and Synthesis**: Generative AI can be used to improve speech recognition systems and generate synthetic voices for use in voice assistants, podcasts, and audiobooks.\n",
      "10. **Creative Writing**: Generative AI can assist writers with content creation, such as generating ideas, outlining articles, or even composing entire pieces of writing.\n",
      "\n",
      "Some industries that are already leveraging generative AI include:\n",
      "\n",
      "1. **Finance**: Using generative AI to analyze financial data, predict market trends, and create personalized investment advice.\n",
      "2. **Healthcare**: Using generative AI to develop personalized treatment plans, generate medical images, and predict patient outcomes.\n",
      "3. **Retail**: Using generative AI to personalize product recommendations, improve inventory management, and create immersive customer experiences.\n",
      "4. **Education**: Using generative AI to create personalized learning content, grade assignments, and provide feedback.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications that can transform various industries and enhance customer experiences. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can create high-quality, engaging content such as articles, social media posts, and even entire books. This can help businesses save time and resources on content creation, particularly for less complex or repetitive content.\n",
      "2. **Personalized Customer Experiences**: Generative AI can be used to generate personalized product recommendations, tailored advice, and customized marketing messages. For instance, a company like Amazon uses machine learning algorithms to suggest products based on user browsing history and purchase behavior.\n",
      "3. **Chatbots and Conversational Interfaces**: Generative AI enables the development of more advanced chatbots that can engage with customers in a natural, human-like way. This can improve customer service, provide 24/7 support, and even help with transactions like booking flights or ordering food delivery.\n",
      "4. **Image and Video Generation**: Generative AI can create realistic images, videos, or animations for various purposes such as product design, marketing campaigns, or entertainment. Companies like Disney and Pixar use generative AI to create stunning visuals for their films and TV shows.\n",
      "5. **Speech Synthesis and Text-to-Speech**: Generative AI can generate high-quality speech with precise tone, pitch, and expression. This technology is increasingly used in applications such as voice assistants, audiobooks, and virtual reality experiences.\n",
      "6. **Product Design and Prototyping**: Generative AI can rapidly create 3D models, prototypes, and even functional designs for products. This can save companies like IKEA or Apple significant time and resources on traditional design processes.\n",
      "7. **Risk Management and Compliance**: Generative AI can help identify potential risks and violations of regulations by analyzing large datasets and identifying patterns. For instance, insurance companies use generative AI to detect fraud and compliance issues.\n",
      "8. **Music and Audio Creation**: Generative AI can compose original music, generate beats, or even create entire audio tracks for various applications such as film scores, video games, or commercials.\n",
      "9. **Medical Imaging Analysis**: Generative AI can help analyze medical images like X-rays, CT scans, or MRI scans to identify patterns and anomalies that may indicate diseases or conditions.\n",
      "10. **Facial Recognition and Emotion Analysis**: Generative AI can be used to create systems that recognize and analyze human emotions, such as facial expressions, body language, or tone of voice.\n",
      "\n",
      "Some specific use cases in various industries include:\n",
      "\n",
      "* Fashion: creating personalized clothing designs, generating product prototypes\n",
      "* Healthcare: analyzing medical images, detecting diseases early\n",
      "* Education: generating personalized learning content, grading assignments automatically\n",
      "* Finance: identifying credit score risks, predicting stock market trends\n",
      "* Retail: recommending products, suggesting prices\n",
      "\n",
      "These applications demonstrate the potential of Generative AI to transform various business processes and improve customer experiences.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏    0 B/1.1 GB                  \u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏    0 B/1.1 GB                  \u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏    0 B/1.1 GB                  \u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 4.4 MB/1.1 GB                  \u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏  13 MB/1.1 GB                  \u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏  15 MB/1.1 GB                  \u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏  28 MB/1.1 GB                  \u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏  37 MB/1.1 GB                  \u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏  41 MB/1.1 GB                  \u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏  45 MB/1.1 GB                  \u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏  57 MB/1.1 GB   57 MB/s     18s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏  57 MB/1.1 GB   57 MB/s     18s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏  61 MB/1.1 GB   57 MB/s     18s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏  68 MB/1.1 GB   57 MB/s     18s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏  81 MB/1.1 GB   57 MB/s     18s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏  83 MB/1.1 GB   57 MB/s     17s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏  87 MB/1.1 GB   57 MB/s     17s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 103 MB/1.1 GB   57 MB/s     17s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 114 MB/1.1 GB   57 MB/s     17s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 123 MB/1.1 GB   57 MB/s     17s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 128 MB/1.1 GB   57 MB/s     17s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 137 MB/1.1 GB   66 MB/s     14s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 147 MB/1.1 GB   66 MB/s     14s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 151 MB/1.1 GB   66 MB/s     14s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 154 MB/1.1 GB   66 MB/s     14s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 167 MB/1.1 GB   66 MB/s     14s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 171 MB/1.1 GB   66 MB/s     14s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 176 MB/1.1 GB   66 MB/s     14s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 187 MB/1.1 GB   66 MB/s     13s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 192 MB/1.1 GB   66 MB/s     13s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 202 MB/1.1 GB   66 MB/s     13s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 211 MB/1.1 GB   68 MB/s     13s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 216 MB/1.1 GB   68 MB/s     13s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 225 MB/1.1 GB   68 MB/s     12s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 235 MB/1.1 GB   68 MB/s     12s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 238 MB/1.1 GB   68 MB/s     12s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 249 MB/1.1 GB   68 MB/s     12s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 258 MB/1.1 GB   68 MB/s     12s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 263 MB/1.1 GB   68 MB/s     12s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 269 MB/1.1 GB   68 MB/s     12s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 281 MB/1.1 GB   68 MB/s     12s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 286 MB/1.1 GB   71 MB/s     11s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 297 MB/1.1 GB   71 MB/s     11s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 306 MB/1.1 GB   71 MB/s     11s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 311 MB/1.1 GB   71 MB/s     11s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 321 MB/1.1 GB   71 MB/s     11s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 330 MB/1.1 GB   71 MB/s     10s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 334 MB/1.1 GB   71 MB/s     10s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 339 MB/1.1 GB   71 MB/s     10s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 347 MB/1.1 GB   71 MB/s     10s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 347 MB/1.1 GB   71 MB/s     10s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 362 MB/1.1 GB   72 MB/s     10s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 368 MB/1.1 GB   72 MB/s     10s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 376 MB/1.1 GB   72 MB/s     10s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 386 MB/1.1 GB   72 MB/s     10s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 396 MB/1.1 GB   72 MB/s      9s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 401 MB/1.1 GB   72 MB/s      9s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 410 MB/1.1 GB   72 MB/s      9s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 420 MB/1.1 GB   72 MB/s      9s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 423 MB/1.1 GB   72 MB/s      9s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 427 MB/1.1 GB   72 MB/s      9s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 440 MB/1.1 GB   73 MB/s      9s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 444 MB/1.1 GB   73 MB/s      9s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 454 MB/1.1 GB   73 MB/s      9s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 458 MB/1.1 GB   73 MB/s      8s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 465 MB/1.1 GB   73 MB/s      8s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 470 MB/1.1 GB   73 MB/s      8s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 475 MB/1.1 GB   73 MB/s      8s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 480 MB/1.1 GB   73 MB/s      8s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 488 MB/1.1 GB   73 MB/s      8s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 498 MB/1.1 GB   73 MB/s      8s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 503 MB/1.1 GB   73 MB/s      8s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 512 MB/1.1 GB   72 MB/s      8s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 520 MB/1.1 GB   72 MB/s      8s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 523 MB/1.1 GB   72 MB/s      8s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 530 MB/1.1 GB   72 MB/s      8s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 540 MB/1.1 GB   72 MB/s      7s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 544 MB/1.1 GB   72 MB/s      7s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 553 MB/1.1 GB   72 MB/s      7s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 562 MB/1.1 GB   72 MB/s      7s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 567 MB/1.1 GB   72 MB/s      7s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 576 MB/1.1 GB   72 MB/s      7s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 580 MB/1.1 GB   72 MB/s      7s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 585 MB/1.1 GB   72 MB/s      7s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 598 MB/1.1 GB   72 MB/s      7s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 608 MB/1.1 GB   72 MB/s      7s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 613 MB/1.1 GB   72 MB/s      6s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 623 MB/1.1 GB   72 MB/s      6s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 630 MB/1.1 GB   72 MB/s      6s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 632 MB/1.1 GB   72 MB/s      6s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 647 MB/1.1 GB   72 MB/s      6s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 656 MB/1.1 GB   72 MB/s      6s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 658 MB/1.1 GB   73 MB/s      6s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 670 MB/1.1 GB   73 MB/s      6s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 680 MB/1.1 GB   73 MB/s      5s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 685 MB/1.1 GB   73 MB/s      5s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 694 MB/1.1 GB   73 MB/s      5s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 704 MB/1.1 GB   73 MB/s      5s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 709 MB/1.1 GB   73 MB/s      5s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 717 MB/1.1 GB   73 MB/s      5s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 727 MB/1.1 GB   73 MB/s      5s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 732 MB/1.1 GB   73 MB/s      5s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 741 MB/1.1 GB   75 MB/s      4s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 751 MB/1.1 GB   75 MB/s      4s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 755 MB/1.1 GB   75 MB/s      4s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 762 MB/1.1 GB   75 MB/s      4s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 770 MB/1.1 GB   75 MB/s      4s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 775 MB/1.1 GB   75 MB/s      4s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 785 MB/1.1 GB   75 MB/s      4s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 794 MB/1.1 GB   75 MB/s      4s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 798 MB/1.1 GB   75 MB/s      4s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 803 MB/1.1 GB   75 MB/s      4s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 814 MB/1.1 GB   75 MB/s      4s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 816 MB/1.1 GB   75 MB/s      3s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 827 MB/1.1 GB   75 MB/s      3s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 833 MB/1.1 GB   75 MB/s      3s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 837 MB/1.1 GB   75 MB/s      3s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 847 MB/1.1 GB   75 MB/s      3s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 856 MB/1.1 GB   75 MB/s      3s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 861 MB/1.1 GB   75 MB/s      3s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 865 MB/1.1 GB   75 MB/s      3s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 876 MB/1.1 GB   75 MB/s      3s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 879 MB/1.1 GB   75 MB/s      3s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 888 MB/1.1 GB   75 MB/s      3s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 898 MB/1.1 GB   75 MB/s      2s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     ▏ 903 MB/1.1 GB   75 MB/s      2s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest █   ▏ 913 MB/1.1 GB   75 MB/s      2s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest █   ▏ 923 MB/1.1 GB   75 MB/s      2s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest █   ▏ 927 MB/1.1 GB   75 MB/s      2s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest █   ▏ 936 MB/1.1 GB   75 MB/s      2s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest █   ▏ 946 MB/1.1 GB   75 MB/s      2s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest █   ▏ 950 MB/1.1 GB   75 MB/s      2s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest █   ▏ 960 MB/1.1 GB   75 MB/s      2s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest █   ▏ 969 MB/1.1 GB   75 MB/s      1s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest █   ▏ 974 MB/1.1 GB   75 MB/s      1s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ██  ▏ 983 MB/1.1 GB   75 MB/s      1s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ██  ▏ 993 MB/1.1 GB   75 MB/s      1s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ██  ▏ 998 MB/1.1 GB   75 MB/s      1s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ██  ▏ 1.0 GB/1.1 GB   75 MB/s      1s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ██  ▏ 1.0 GB/1.1 GB   75 MB/s      1s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ██  ▏ 1.0 GB/1.1 GB   75 MB/s      1s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ██  ▏ 1.0 GB/1.1 GB   75 MB/s      1s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ██  ▏ 1.0 GB/1.1 GB   75 MB/s      1s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ██  ▏ 1.0 GB/1.1 GB   75 MB/s      1s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ███ ▏ 1.0 GB/1.1 GB   75 MB/s      0s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ███ ▏ 1.1 GB/1.1 GB   75 MB/s      0s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ███ ▏ 1.1 GB/1.1 GB   75 MB/s      0s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ███ ▏ 1.1 GB/1.1 GB   75 MB/s      0s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ███ ▏ 1.1 GB/1.1 GB   75 MB/s      0s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ███ ▏ 1.1 GB/1.1 GB   75 MB/s      0s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ███ ▏ 1.1 GB/1.1 GB   75 MB/s      0s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ███ ▏ 1.1 GB/1.1 GB   75 MB/s      0s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ███ ▏ 1.1 GB/1.1 GB   75 MB/s      0s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ███ ▏ 1.1 GB/1.1 GB   74 MB/s      0s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ███ ▏ 1.1 GB/1.1 GB   74 MB/s      0s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ███ ▏ 1.1 GB/1.1 GB   74 MB/s      0s\u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ████▏ 1.1 GB                         \u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ████▏ 1.1 GB                         \u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ████▏ 1.1 GB                         \u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ████▏ 1.1 GB                         \u001b[?25h\n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest ████▏ 1.1 GB                         \u001b[?25h\n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     \u001b[?25h\n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest     \u001b[?25h\n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \n",
      "\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to write about how the neural network in an LLM works, my understanding is not super strong. Let me see if I can figure this out step by step.\n",
      "\n",
      "First off, what exactly are LLMs? They're those large language models that can understand and generate human-level text, right? So they usually start from some kind of core concept. Wait, I think one major part involved is a neural network. But not just any neural network—how big is it?\n",
      "\n",
      "I remember the assistant said \"a large multi-layered (deep) neural network.\" Hmm, layers in a neural network mean multiple nodes connected together where each layer processes information passed from the previous layer. So maybe that's a multi-layered structure? And being multi-layered suggests deep learning.\n",
      "\n",
      "But what about attention and transformers specifically? I'm not entirely clear on those yet. Let me think.\n",
      "\n",
      "Attention refers to how models focus on certain parts of the input data when making predictions. Like, when generating text, it might decide which word is most relevant next. So it's a way for the neural network to weigh different parts of the input dynamically. Is that right? I'm not sure though; maybe attention isn't the only thing.\n",
      "\n",
      "Then there's the transformer architecture. transformers are these architectures where you break the data into chunks, or tokens, and process them one by one. Each token is processed independently but they also have some way to maintain context across time steps—so something like memory or an internal state that accumulates over time. I think this is because recurrent neural networks, which process sequences step by step, aren't great for capturing long-range dependencies, so transformers did better with that.\n",
      "\n",
      "So combining all that, the LLM probably uses a large multi-layered (deep) neural network that employs attention mechanisms and a transformer architecture to handle both the local features of the text tokens and maintain context over time. This seems to align with what I've heard before—like how BERT or GPT uses these architectures.\n",
      "\n",
      "Wait, though. How do they actually combine all that into such powerful models? Do they use something like self-attention in each layer, capturing long-range dependencies without getting too stuck on individual sentences? Or are there other mechanisms involved?\n",
      "\n",
      "I think the basic structure involves multiple layers processing different parts of the text or image using features extracted from those. But the specifics depend a lot on how the attention and transformers are integrated—maybe something like multi-head attention to process all dimensions at once, adding more flexibility.\n",
      "\n",
      "So putting it all together, the core concepts seem to be:\n",
      "\n",
      "1. **Large Multi-Layer Network**: The neural network is quite deep, with multiple layers each containing nodes processing information. This depth allows for capturing intricate patterns in data.\n",
      "\n",
      "2. **Attention Mechanisms**: These allow the model to focus on specific parts of the input when making predictions or decisions. In transformers, this typically uses self-attention across all positions, enabling understanding of both local and global context through scaled dot-product attention.\n",
      "\n",
      "3. **Transformer Architecture**: A sequence of layers where each layer processes its tokens independently but maintains internal state to track shifts in meaning over time or sequences. This internal memory is crucial for handling long-range dependencies like with RNNs alone.\n",
      "\n",
      "I think that's a good start, but I'm still not confident if the transformer captures all necessary dependencies or if attention plays a bigger role. Maybe it's both—attention allows the model to attend to specific positions when updating its state, which itself is processed by the transformers’ architecture.\n",
      "\n",
      "Wait, some sources say that while the core mechanism involves attention and sequence modeling with transformers, it might be augmented with additional layers or components for more effective language understanding. For example, models like GPTs use self-attention mechanisms within their own multi-head block, which can capture interactions between different parts of a token's context.\n",
      "\n",
      "So overall, without knowing all the specific advancements and innovations in each model, this is an accurate summary of how LLM neural networks work.\n",
      "</think>\n",
      "\n",
      "The underlying core concepts of Large Language Models (LLMs) involve several key components working together to enable their ability to process and generate human-level text. Here's a structured summary:\n",
      "\n",
      "1. **Neural Network Structure**: The core of an LLM consists of a large, multi-layered (deep) neural network. These layers are designed to integrate features from different parts of an input piece of data, allowing the model to recognize patterns and relationships that might appear in isolated contexts.\n",
      "\n",
      "2. **Attention Mechanisms**: When making predictions or decisions, the model employs attention mechanisms. Specifically, transformers use self-attention across all positions, enabling them to focus on specific parts of the input when processing tokens independently but maintaining context through an internal memory state. This mechanism is crucial for capturing long-range dependencies and understanding relationships between different parts of a text.\n",
      "\n",
      "3. **Transformer Architecture**: The architecture of transformers involves processing each token sequentially within layers. Each layer consists of multiple heads, which operate on different aspects of the internal state to process their tokens and maintain context over time or sequences. This design allows transformers to effectively handle long-range dependencies compared to traditional recurrent architectures like RNNs.\n",
      "\n",
      "These components work together to form a powerful framework that enables LLMs to leverage deep learning for sophisticated language processing tasks, with notable contributions from models like GPT, which utilize self-attention mechanisms and transformer architecture patterns.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"neural network\": {\n",
      "    \"description\": \"A large, multi-layered (deep) neural network designed to process high-dimensional data.\"\n",
      "  },\n",
      "  \"attention mechanism\": {\n",
      "    \"key\": \"self-attention\",\n",
      "    \"description\": \"A mechanism where each token's output is conditioned on its own and all other tokens in the sequence, allowing for global context maintenance.\"\n",
      "  },\n",
      "  \"transformer architecture\": {\n",
      "    \"description\": \"A sequential processing system within each layer that processes tokens while maintaining internal state through context learning.\"\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "55e5d8e2-a077-4680-acc8-bed317ac16a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODELS= {1:\"llama3.2\",2:\"deepseek-r1:1.5b\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "45f5139e-4f17-446d-b000-841e7212454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        print(\"<<<<<<<<<<Response from url has been obtained<<<<<<<<<<<<<<<<<\")\n",
    "        print(response)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        print(\"<<<<<<<<<<Parsing Complete. Starting Decomposition<<<<<<<<<<<<<<<<<\")\n",
    "        #print(soup)\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        print(\">>>>>>>>>>>>>>Scraping Complete>>>>>>>>\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8be7e80f-dee1-46db-ab96-00b0a82fe058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b29a77f6-883d-4d32-bfc5-e9a57cc4e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "def user_prompt_for(website):\n",
    "    print(\">>>>>>>>>>>>>Generating User promt>>>>>>\")\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "de3a2390-6e74-4ffe-bfac-8b3cb505610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "99f62a74-9926-4794-95a6-d8ba3b7ae805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with_openai(url,client, MODEL):\n",
    "    website = Website(url)\n",
    "    response = client.chat.completions.create(\n",
    "        model = MODEL,\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def summarize_with_ollama(url,client,MODEL):\n",
    "    website = Website(url)\n",
    "     \n",
    "    response = ollama.chat(\n",
    "        model = MODEL,\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response['message']['content']\n",
    "\n",
    "def summarize(url, MODEL, client=None):\n",
    "    website = Website(url)\n",
    "    if client:\n",
    "        print(f\"{client} specified. We will use this!!\")\n",
    "        response = client.chat.completions.create(\n",
    "            model = MODEL,\n",
    "            messages = messages_for(website)\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    else:\n",
    "        print(\"We will be using Ollama since no client specified\")\n",
    "        response = ollama.chat(\n",
    "        model = MODEL,\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "        return response['message']['content']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2f1da8b6-b68a-4059-8e4b-5eb65756e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url, MODEL, client=None ):\n",
    "    #summary = summarize_with_openai(url,client, MODEL)\n",
    "    #summary = summarize_with_ollama(url,client, MODEL)\n",
    "    summary=summarize(url,MODEL,client)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4433d874-aee1-4d64-b6cc-9468b4d33297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<Response from url has been obtained<<<<<<<<<<<<<<<<<\n",
      "<Response [200]>\n",
      "<<<<<<<<<<Parsing Complete. Starting Decomposition<<<<<<<<<<<<<<<<<\n",
      ">>>>>>>>>>>>>>Scraping Complete>>>>>>>>\n",
      "We will be using Ollama since no client specified\n",
      ">>>>>>>>>>>>>Generating User promt>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Website Summary: Edward Donner's Home Page\n",
       "\n",
       "#### About the Owner\n",
       "Ed is a writer, coder, and DJ who co-founded Nebula.io, applying AI to help people discover their potential. He also has experience as the founder and CEO of an AI startup acquired in 2021.\n",
       "\n",
       "#### News/Announcements\n",
       "* January 23, 2025: LLM Workshop – Hands-on with Agents – resources\n",
       "* December 21, 2024: Welcome, SuperDataScientists!\n",
       "* November 13, 2024: Mastering AI and LLM Engineering – Resources\n",
       "* October 16, 2024: From Software Engineer to AI Data Scientist – resources\n",
       "\n",
       "#### Website Features\n",
       "* **Outsmart**: An arena that pits LLMs against each other in a battle of diplomacy and deviousness.\n",
       "* Connect Four game not accessible as it is only marked with links.\n",
       "* Blog sections for various topics, but the specific articles are not visible.\n",
       "\n",
       "### Contact Information\n",
       "Email: [ed at] edwarddonner [dot] com\n",
       "Website: www.edwarddonner.com\n",
       "LinkedIn | Twitter | Facebook"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url=\"https://edwarddonner.com\"#\"https://anthropic.com\" #\n",
    "MODEL=MODELS[1]\n",
    "display_summary(url,MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "68928712-a7a5-44fc-9067-1a845e9c6f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<Response from url has been obtained<<<<<<<<<<<<<<<<<\n",
      "<Response [200]>\n",
      "<<<<<<<<<<Parsing Complete. Starting Decomposition<<<<<<<<<<<<<<<<<\n",
      ">>>>>>>>>>>>>>Scraping Complete>>>>>>>>\n",
      "<openai.OpenAI object at 0x12086c350> specified. We will use this!!\n",
      ">>>>>>>>>>>>>Generating User promt>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Website Summary\n",
       "\n",
       "This website belongs to Ed Donner, a co-founder and CTO of Nebula.io. The content is comprised of:\n",
       "\n",
       "* An introductory post about Ed's interests, work, and experiences in the AI field.\n",
       "* A brief overview of his current role at Nebula.io, where he applies AI to help people discover their potential.\n",
       "* Links to some of Ed's recent talks and workshops, including:\n",
       "\t+ LLM Workshop – Hands-on with Agents (January 2025)\n",
       "\t+ Welcome, SuperDataScientists! (November 2024)\n",
       "\t+ Mastering AI and LLM Engineering – Resources (October 2024)\n",
       "\t+ From Software Engineer to AI Data Scientist – resources\n",
       "\n",
       "The website seems to be Ed's personal blog or professional homepage, showcasing his expertise in AI and providing a glimpse into his work at Nebula.io."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url=\"https://edwarddonner.com\"#\"https://anthropic.com\" #\n",
    "MODEL=MODELS[1]\n",
    "display_summary(url,MODEL,client=openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3c4036c8-f442-4a81-930e-5cf2da46ed1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<Response from url has been obtained<<<<<<<<<<<<<<<<<\n",
      "<Response [200]>\n",
      "<<<<<<<<<<Parsing Complete. Starting Decomposition<<<<<<<<<<<<<<<<<\n",
      ">>>>>>>>>>>>>>Scraping Complete>>>>>>>>\n",
      "We will be using Ollama since no client specified\n",
      ">>>>>>>>>>>>>Generating User promt>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Alright, I need to create a markdown summary of the given website. Let's start by reading through the content carefully.\n",
       "\n",
       "The main sections are \"About\" and \"Posts.\" The page seems to be about LLMs (Large Language Models) with various activities like Connect Four, Outsmart, and a Connect section for different workshops and events.\n",
       "\n",
       "In the \"About\" section, it mentions Ed. being the co-founder of Nebula.io. They focus on applying AI in talent discovery. They also list some prior experiences as founder and CEO of untapt, which was acquired by 2021.\n",
       "\n",
       "The \"Posts\" are listed with dates from December 2024 to January 2025, each highlighting different workshops or events related to LLMs.\n",
       "\n",
       "I should structure the summary to include:\n",
       "\n",
       "1. A brief introduction about the site.\n",
       "2. Mention of the main activities (Connect Four, Outsmart).\n",
       "3. Highlight the company (Nebula.io) and their mission with LLMs.\n",
       "4. Include Ed.'s background as co-founder and former CEO.\n",
       "5. List the key events or workshops from December 2024 to January 2025.\n",
       "\n",
       "I'll make sure not to mention anything related to navigation since that's for a separate part of the website. I'll keep it concise but informative, summarizing what users can expect on the site.\n",
       "</think>\n",
       "\n",
       "The website is about LLMs (Large Language Models) and their applications in talent discovery and AI-related activities.\n",
       "\n",
       "- **About**:  \n",
       "  - Ed. is co-founder and CTO of Nebula.io, applying AI to help people discover potential. They focus on talent engineering using LLMs. They've previously led untapt and were acquired in 2021.\n",
       "  \n",
       "- **Highlights**:  \n",
       "  - **Connect Four**: A game that pits LLMs against each other.\n",
       "  - **Outsmart**: An arena where users play with LLMs.\n",
       "\n",
       "- **Key Events (Dec 2024–Jan 2025)**:  \n",
       "  - December 21, 2024: LLM Workshop – Hands-on with Agents and resources.\n",
       "  - November 13, 2024: Mastering AI and LLM Engineering – Resources.\n",
       "  - October 16, 2024: From Software Engineer to AI Data Scientist – resources.\n",
       "\n",
       "The site is a platform for exploring the impact of LLMs on talent discovery."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url=\"https://edwarddonner.com\"#\"https://anthropic.com\" #\n",
    "MODEL=MODELS[2]\n",
    "display_summary(url,MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1cc5e49e-0fa8-4e28-8f1f-883e56bc1ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<Response from url has been obtained<<<<<<<<<<<<<<<<<\n",
      "<Response [200]>\n",
      "<<<<<<<<<<Parsing Complete. Starting Decomposition<<<<<<<<<<<<<<<<<\n",
      ">>>>>>>>>>>>>>Scraping Complete>>>>>>>>\n",
      "<openai.OpenAI object at 0x12086c350> specified. We will use this!!\n",
      ">>>>>>>>>>>>>Generating User promt>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, so I'm trying to write a short summary of this website. Let me see, the Home tab says it's about Connect Four, Outsmart, and an arena where LLMs battle each other. Oh, and there's more details there—like Ed being the co-founder and CTO of Nebula.io. They use LLMs to help find people’s potential.\n",
       "\n",
       "Then, the About section talks about writing code and experimenting with LLMs. They are co-founder and CTO of Nebula.io, which uses AI for talent discovery. There's a workshop on LLMs with hands-on agents, documentation resources, and press coverage. Also, they mention getting in touch via email.\n",
       "\n",
       "At the end, there are links to different workshops, including one from October 16. They're subscribed to a newsletter and follow me on LinkedIn, Twitter, Facebook, etc. So, it's an AI-related site with product demos, educational content, and community support.\n",
       "\n",
       "I should summarize all of this concisely in markdown without any extra text. Maybe something like highlighting the main features: Connect Four-like games, Outsmart system, LLM-based arena. Mention the technologies used—likely Python, TensorFlow, PyTorch, JAX. Also note who runs them—and who's subscribed to their newsletter.\n",
       "</think>\n",
       "\n",
       "This website is focused on a niche AI-driven environment where users can engage in strategic AI-resembling games like Connect Four and Outsmart, with LLMs (Large Language Models) capable of participating in such environments. The platform offers educational content, including demos and resources, centered around the use of TensorFlow for developing intelligent agents. It also hosts workshops on AI technologies, with a workshop titled \"Hands-on with Agents\" providing hands-on experience. Subscripted to their newsletter service is part of an organization (Nebula.io) that leverages AI for talent discovery. The website caters to enthusiasts and professionals interested in utilizing AI in strategic contexts, drawing subscribers from various online platforms including LinkedIn and Twitter."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url=\"https://edwarddonner.com\"#\"https://anthropic.com\" #\n",
    "MODEL=MODELS[2]\n",
    "display_summary(url,MODEL,client=openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b98409c-67ee-465e-b3c1-7d91a49d56e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
